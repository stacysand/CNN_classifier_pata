{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95b5606-3c5e-463d-b8fc-cce931b76aa3",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa39afe-579b-4cbd-8c6c-61d2a666c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchaudio.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import Audio, clear_output, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a624b-adbc-4cba-a58e-ecd314092979",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88195e5e-d308-4aa5-8b9b-cf7453dbfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "\n",
    "    def __init__(self, csv, transform=None):\n",
    "        self.csv = csv\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.transform = transform\n",
    "        # label to index mapping\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(sorted(self.df['label'].unique()))}\n",
    "        self.idx_to_label = {i:l for l,i in self.label_to_idx.items()}\n",
    "        self.class_names = [self.idx_to_label[i] for i in range(len(self.idx_to_label))]\n",
    "        print(f'\\nDataset initialized with: {len(self.df)} samples')\n",
    "        print(f'Label mapping: {self.label_to_idx}')\n",
    "        print(f'Class distribution:\\n{self.df['label'].value_counts()}\\n')\n",
    "\n",
    "    # get total number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # get a single example (image tensor + label index) for a given index\n",
    "    def __getitem__(self, idx):\n",
    "        # load image\n",
    "        image = Image.open(self.df.iloc[idx]['image_path']).convert('RGB')\n",
    "        # apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # get label\n",
    "        label = self.label_to_idx[self.df.iloc[idx]['label']]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3ce7b-a843-4230-b901-99bc60ca3765",
   "metadata": {},
   "source": [
    "# Data preparation and loaders\n",
    "## Data transform & augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffdc3f-9ef0-473b-88de-42732b2a22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(normalize_mean, normalize_std):\n",
    "    # Training transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        # ColorJitter: Brightness, Contrast, Saturation, Hue (N% of variation)\n",
    "        # transforms.ColorJitter(brightness=0.2),\n",
    "        # transforms.ColorJitter(contrast=0.2),\n",
    "        # transforms.ColorJitter(saturation=0.2),\n",
    "        # transforms.ColorJitter(hue=0.1),\n",
    "        # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        # Random Grayscale (with N% probability)\n",
    "        # transforms.RandomGrayscale(p=0.3),\n",
    "        # PIL Image (H×W×C, values 0-255) → PyTorch tensor (C×H×W, values 0.0-1.0)\n",
    "        transforms.ToTensor(),\n",
    "        # standardizes pixel values by formula 'normalized_value=(pixel_value-mean)/std' for each color channel (R,G,B)\n",
    "        transforms.Normalize(mean=normalize_mean, std=normalize_std)\n",
    "    ])\n",
    "\n",
    "    # Validation transforms\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=normalize_mean, std=normalize_std)\n",
    "    ])\n",
    "\n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5aee21-10a3-4d91-9b67-8042734fb710",
   "metadata": {},
   "source": [
    "## Data loaders (train & valid sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c214b7-1fa4-42be-8652-244d86db5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_loaders(csv,\n",
    "                         val_split=0.2, \n",
    "                         batch_size=32, \n",
    "                         normalize_mean=[0.485, 0.456, 0.406], \n",
    "                         normalize_std=[0.229, 0.224, 0.225]\n",
    "                        ):\n",
    "    \n",
    "    # create full ds\n",
    "    full_ds = DS(csv, transform=None)\n",
    "    label_to_idx = full_ds.label_to_idx\n",
    "    \n",
    "    # split into train and validation\n",
    "    val_size = int(val_split * len(full_ds))\n",
    "    train_size = len(full_ds) - val_size\n",
    "    train_ds, val_ds = random_split(full_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    print(f'\\nDataset splits (val_split={val_split}):')\n",
    "    print(f'Training set: {train_size}')\n",
    "    print(f'Validation set: {val_size}\\n')\n",
    "    \n",
    "    # dataset transform\n",
    "    train_transform, val_transform = get_transforms(normalize_mean, normalize_std)\n",
    "    train_ds.dataset.transform = train_transform\n",
    "    val_ds.dataset.transform = val_transform\n",
    "\n",
    "    # create data loaders\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343fe5f-ea87-4fff-a846-6370d985348d",
   "metadata": {},
   "source": [
    "# Model Architecture (CNN Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341edf83-c3f5-453b-bfe4-ef049df9364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(SpectrogramCNN, self).__init__()\n",
    "\n",
    "        # 1) convolutional blocks (for each block: ConvLayer + BatchNorm + MaxPooling)\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        # batch normalization\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        # max pooling\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 2) adaptive (global) pooling layer\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        # 3) fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # 2 classes for output\n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        print('\\nSpectrogram (224x224) CNN model')\n",
    "        print('Architecture:')\n",
    "        print('- 4 convolutional blocks (BatchNorm, ReLU, MaxPool)')\n",
    "        print('- global average pooling')\n",
    "        print('- 3 fully connected layers with dropout\\n')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # convolutional blocks\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        # adaptive (global) pooling layer\n",
    "        x = self.global_pool(x)\n",
    "        # flattering the layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fully connected layers (with dropout)\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        x = F.relu(self.fc2(self.dropout(x)))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e686df1-c9f6-49b9-b882-e337cf880f0f",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7618a205-66dd-4908-b29a-c767c60524df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    # start training\n",
    "    model.train()\n",
    "    total_loss = 0.0  # total loss across all batches\n",
    "    total_samples = 0  # total samples processed\n",
    "    total_correct = 0  # correct predictions\n",
    "\n",
    "    # initialize progress bar\n",
    "    pbar = tqdm(train_loader, desc='Training', leave=False)  # remove bar after complition\n",
    "\n",
    "    # loop for processing data in batches\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):  # 'enumerate' gives both item and idx when looping\n",
    "        optimizer.zero_grad()  # reset grads before next calculation\n",
    "        # forward pass\n",
    "        outputs = model(images)  # get preds\n",
    "        loss = criterion(outputs, labels)  # calculate loss\n",
    "        # backward pass\n",
    "        loss.backward()  # compute grads \n",
    "        optimizer.step()  # update weights\n",
    "        # stats\n",
    "        total_loss += loss.item()  # accumulate loss across batches (here, loss tensor becomes regular Py num)\n",
    "        total_samples += labels.size(0)  # add to total count of samples processed num of samples in this batch (1st dimension)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # find max val and its idx in each row of outputs, get only latter\n",
    "        total_correct += (predicted == labels).sum().item()  # create boolean tensor, count true vals, convert into Py num, add to total\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100. * total_correct / total_samples:.2f}%'})\n",
    "\n",
    "    # epoch averages\n",
    "    epoch_loss = total_loss / len(train_loader)  # divide by num of batches in train data\n",
    "    epoch_acc = 100. * total_correct / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e330a7-fa56-4688-9365-59884587f3fc",
   "metadata": {},
   "source": [
    "# Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf26a7b-0095-419e-afa7-50b3a81b7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion):\n",
    "    # start validation\n",
    "    model.eval()\n",
    "    total_loss = 0.0  # total loss across all batches\n",
    "    total_samples = 0  # total samples processed\n",
    "    total_correct = 0  # correct predictions\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    # initialize progress bar\n",
    "    pbar = tqdm(val_loader, desc='Validation', leave=False)  # progress-bar-wrapped version of val_loader\n",
    "\n",
    "    with torch.no_grad():  # don't calculate grads\n",
    "        for images, labels in pbar:\n",
    "            # forward pass\n",
    "            outputs = model(images)  # get preds\n",
    "            loss = criterion(outputs, labels)  # calculate loss\n",
    "            # stats\n",
    "            total_loss += loss.item()  # accumulate loss across batches (here, loss tensor becomes regular Py num)\n",
    "            total_samples += labels.size(0)  # add to total count of samples processed num of samples in this batch (1st dimension)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # find max val and its idx in each row of outputs, get only latter\n",
    "            total_correct += (predicted == labels).sum().item()  # create boolean tensor, count true vals, convert into Py num, add to total\n",
    "            # store preds and labels\n",
    "            all_predictions.extend(predicted.numpy())  # convert to NumPy array, add to list\n",
    "            all_labels.extend(labels.numpy())  # convert to NumPy array, add to list\n",
    "\n",
    "            # update progress bar\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100. * total_correct / total_samples:.2f}%'})\n",
    "\n",
    "    # epoch averages\n",
    "    epoch_loss = total_loss / len(val_loader)  # divide by num of batches in valid data\n",
    "    epoch_acc = 100. * total_correct / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7679c9-d703-4c5c-9a62-0c0fcd4bfddf",
   "metadata": {},
   "source": [
    "# Main train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c96518-51cb-4b72-a858-c1ad48491af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                num_epochs,\n",
    "                scheduler,\n",
    "                patience_epochs=10,\n",
    "                save_path='/Users/hela/Code/pata/best_model.pth'\n",
    "               ):\n",
    "    \n",
    "    trained_model = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}  # dict for graphs\n",
    "    best_val_acc = 0.0\n",
    "    patience = patience_epochs  # wait N epochs without improvement before stopping\n",
    "    patience_counter = 0  # count epochs without improvement\n",
    "\n",
    "    print('\\n'+'='*70)\n",
    "    print('Training')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    # loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "        # training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        # validation\n",
    "        val_loss, val_acc, _, _ = validate_epoch(model, val_loader, criterion)\n",
    "        # update lr\n",
    "        scheduler.step(val_loss)  # adjust lr if val_loss doesn't improve\n",
    "        \n",
    "        # print results\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # save history for graphs\n",
    "        trained_model['train_loss'].append(train_loss)\n",
    "        trained_model['train_acc'].append(train_acc)\n",
    "        trained_model['val_loss'].append(val_loss)\n",
    "        trained_model['val_acc'].append(val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({'epoch':epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'val_acc': val_acc,\n",
    "                        'val_loss': val_loss},\n",
    "                       save_path)\n",
    "            print(f\"✓ Model saved. (Val Acc: {val_acc:.2f}%)\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print('\\n'+'='*70)\n",
    "    print('Training completed')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91a51c-b4c7-4a39-9a94-66da57626b70",
   "metadata": {},
   "source": [
    "# Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2394667-a4d0-47da-a005-9e3413ef8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, load_path='/Users/hela/Code/pata/best_model.pth'):\n",
    "    checkpoint = torch.load(load_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"\\nBest model from: epoch {checkpoint['epoch']+1}\")\n",
    "    print(f\"Validation Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    print(f\"Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef61bd4-7262-42f0-82f8-dac3192c4d80",
   "metadata": {},
   "source": [
    "# Evaluate preds\n",
    "## Get preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3690ab-4029-4560-91fa-090ea813e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(trained_model, path_img, class_names=['pa','ta']):\n",
    "    # load image\n",
    "    image = Image.open(path_img).convert('RGB')\n",
    "\n",
    "    # transform (tensor)\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image_tensor = test_transform(image).unsqueeze(0)\n",
    "\n",
    "    # get results\n",
    "    with torch.no_grad():\n",
    "        outputs = trained_model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        confidence, prediction = torch.max(probabilities, 1)\n",
    "        label = class_names[prediction.item()]\n",
    "    \n",
    "    #return prediction.item(), confidence.item(), probabilities.numpy()[0]\n",
    "    return image, confidence, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45054a-2cd9-41cc-9707-3d12a2ba6dee",
   "metadata": {},
   "source": [
    "## Visualize preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a475561-0492-4e73-ac8c-6255737d51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predict(trained_model, csv_file='/Users/hela/Code/pata/data_labeling.csv'):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    row_index = None\n",
    "    label = None\n",
    "    confidence = None\n",
    "        \n",
    "    def set_new_trial():\n",
    "        nonlocal row_index, label, confidence\n",
    "        # get unlabeled trials only\n",
    "        unlabeled_trials = df[df['label'].isna()]\n",
    "        # select random row and corresponding file info\n",
    "        rand_row = unlabeled_trials.sample(n=1)\n",
    "        row_index = rand_row.index[0]\n",
    "        path_audio = rand_row['audio_path'].iloc[0]\n",
    "        path_img = rand_row['image_path'].iloc[0]\n",
    "        # get prediction\n",
    "        image, confidence, label = predict_image(trained_model, path_img)\n",
    "        # display example and results\n",
    "        print(f'File name: {rand_row['name'].iloc[0]}')\n",
    "        print(f'Prediction: {label}\\nConfidence: {confidence.item():.2f}')\n",
    "        display(Audio(path_audio, autoplay=True))\n",
    "        display(image)\n",
    "        print(df['label'].value_counts())\n",
    "        print(df['label'].notna().sum(), '/', 8640, 'labeled trials.')\n",
    "        \n",
    "    def update_display():\n",
    "        with output: \n",
    "            clear_output()\n",
    "            set_new_trial()\n",
    "                \n",
    "    # Widgets\n",
    "    output = widgets.Output()\n",
    "    button_corr = widgets.Button(description = '✅')\n",
    "    button_incorr = widgets.Button(description = '❌')\n",
    "    button_err = widgets.Button(description = 'Broken')\n",
    "    button_next = widgets.Button(description = '->')\n",
    "    button_stop = widgets.Button(description = 'Save progress')\n",
    "    display(widgets.HBox([button_incorr, button_corr]))\n",
    "    display(widgets.HBox([button_err, button_next]))\n",
    "    display(widgets.HBox([output]))\n",
    "    display(widgets.HBox([button_stop]))\n",
    "    \n",
    "    def click_corr(_):\n",
    "        with output:\n",
    "            df.at[row_index, 'label'] = label\n",
    "            update_display()\n",
    "    button_corr.on_click(click_corr)\n",
    "\n",
    "    def click_incorr(_):\n",
    "        with output:\n",
    "            opposite_label = 'ta' if label == 'pa' else 'pa'\n",
    "            df.at[row_index, 'label'] = opposite_label\n",
    "            update_display()\n",
    "    button_incorr.on_click(click_incorr)\n",
    "    \n",
    "    def click_err(_):\n",
    "        with output:\n",
    "            df.at[row_index, 'label'] = 'err'\n",
    "            update_display()\n",
    "    button_err.on_click(click_err)\n",
    "\n",
    "    def click_next(_):\n",
    "        with output:\n",
    "            update_display()\n",
    "    button_next.on_click(click_next)\n",
    "\n",
    "    def click_stop(_):\n",
    "        with output:\n",
    "            df.to_csv('/Users/hela/Code/pata/data_labeling.csv', index=False)\n",
    "            print('New predictions are saved.')\n",
    "    button_stop.on_click(click_stop)\n",
    "\n",
    "    # Start\n",
    "    update_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03673c2a-d039-472f-affa-491434b44673",
   "metadata": {},
   "source": [
    "# Final table\n",
    "## Predict table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de71d51-82dd-4ae7-aa7d-7580e7cd66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_table(trained_model, csv_file='/Users/hela/Code/pata/data_labeling.csv'):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df_preds = df[df['label'].isna()]\n",
    "    \n",
    "    preds = []\n",
    "    confs = []\n",
    "    \n",
    "    for idx, row in tqdm(df_preds.iterrows(), total=len(df_preds)):\n",
    "        path_img = row['image_path']\n",
    "        _, confidence, label = predict_image(trained_model, path_img)\n",
    "        preds.append(label)\n",
    "        confs.append(confidence.item())\n",
    "        \n",
    "    df_preds['predict'] = preds\n",
    "    df_preds['confidence'] = confs\n",
    "\n",
    "    df_preds.to_csv('/Users/hela/Code/pata/data_predicted.csv', index=False)\n",
    "    print(\"CSV file with predicted labels is saved as 'data_predicted.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9834eb-9519-45fd-b9f3-dbe433a86f1d",
   "metadata": {},
   "source": [
    "## Eval predict table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21ac932-1c04-400d-b478-5af21f905425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_predict_table(csv_file='/Users/hela/Code/pata/data_predicted.csv', conf_low=0, conf_high=1, unchecked_only=True):\n",
    "    df_original = pd.read_csv(csv_file)\n",
    "    df_filtered = df_original[(df_original['confidence'] > conf_low) & (df_original['confidence'] < conf_high)]\n",
    "    row_index = None\n",
    "    label = None\n",
    "    confidence = None\n",
    "        \n",
    "    def set_new_trial():\n",
    "        nonlocal row_index, label, df_filtered\n",
    "        # check condition\n",
    "        if unchecked_only == False:\n",
    "            df_to_sample = df_filtered\n",
    "        else:\n",
    "            df_to_sample = df_filtered[df_filtered['label'].isna()]\n",
    "        # check condition\n",
    "        if len(df_to_sample) == 0:\n",
    "            print(f'No unchecked trials with confidence from {conf_low} to {conf_high}: {len(df_to_sample)}')\n",
    "            return\n",
    "        # select random row and corresponding file info\n",
    "        rand_row = df_to_sample.sample(n=1)\n",
    "        row_index = rand_row.index[0]\n",
    "        path_audio = rand_row['audio_path'].iloc[0]\n",
    "        path_img = rand_row['image_path'].iloc[0]\n",
    "        label = rand_row['predict'].iloc[0]\n",
    "        image = Image(path_img)\n",
    "        # display example and results\n",
    "        print(f'Selected trials with confidence from {conf_low} to {conf_high}: {len(df_to_sample)}')\n",
    "        print('-' * 30)\n",
    "        print(f'File name: {rand_row['name'].iloc[0]}')\n",
    "        print(f'Prediction: {label}\\nConfidence: {rand_row['confidence'].iloc[0]:.2f}')\n",
    "        display(Audio(path_audio, autoplay=True))\n",
    "        display(image)\n",
    "    \n",
    "    def update_display():\n",
    "        with output:\n",
    "            clear_output()\n",
    "            set_new_trial()\n",
    "                \n",
    "    # Widgets\n",
    "    output = widgets.Output()\n",
    "    button_corr = widgets.Button(description = '✅')\n",
    "    button_incorr = widgets.Button(description = '❌')\n",
    "    button_err = widgets.Button(description = 'Broken')\n",
    "    button_next = widgets.Button(description = '->')\n",
    "    button_stop = widgets.Button(description = 'Save progress')\n",
    "    display(widgets.HBox([button_incorr, button_corr]))\n",
    "    display(widgets.HBox([button_err, button_next]))\n",
    "    display(widgets.HBox([output]))\n",
    "    display(widgets.HBox([button_stop]))\n",
    "\n",
    "    def click_corr(_):\n",
    "        with output:\n",
    "            df_original.at[row_index, 'label'] = label\n",
    "            df_filtered.at[row_index, 'label'] = label\n",
    "            update_display()\n",
    "    button_corr.on_click(click_corr)\n",
    "    \n",
    "    def click_incorr(_):\n",
    "        with output:\n",
    "            opposite_label = 'ta' if label == 'pa' else 'pa'\n",
    "            df_original.at[row_index, 'label'] = opposite_label\n",
    "            df_filtered.at[row_index, 'label'] = opposite_label\n",
    "            update_display()\n",
    "    button_incorr.on_click(click_incorr)\n",
    "    \n",
    "    def click_err(_):\n",
    "        with output:\n",
    "            df_original.at[row_index, 'label'] = 'err'\n",
    "            df_filtered.at[row_index, 'label'] = 'err'\n",
    "            update_display()\n",
    "    button_err.on_click(click_err)\n",
    "\n",
    "    def click_next(_):\n",
    "        with output:\n",
    "            update_display()\n",
    "    button_next.on_click(click_next)\n",
    "\n",
    "    def click_stop(_):\n",
    "        with output:\n",
    "            df_original.to_csv('/Users/hela/Code/pata/data_predicted.csv', index=False)\n",
    "            print('Corrected predictions are saved.')\n",
    "    button_stop.on_click(click_stop)\n",
    "\n",
    "    # Start\n",
    "    update_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8db37-6b0b-4f93-99df-8e1e47c186d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
