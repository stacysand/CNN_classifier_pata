{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd7ce40-9fb8-4204-b8e3-c216c69185aa",
   "metadata": {},
   "source": [
    "# Main training loop\n",
    "The orchestrator that coordinates everything.\n",
    "Contains:\n",
    "- Epoch loop\n",
    "- Calls training function\n",
    "- Calls validation function\n",
    "- Tracks best model\n",
    "- Early stopping logic\n",
    "- Model checkpointing (saving)\n",
    "- Training history tracking (for plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00d5e03-b994-4eed-9f77-87568264438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ef88cb-4ed8-4d0d-a4da-7427a0f221ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler, save_path='/Users/hela/Code/pata/best_model.pth'):\n",
    "    trained_model = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}  # dict for graphs\n",
    "    best_val_acc = 0.0\n",
    "    patience = 10  # wait N epochs without improvement before stopping\n",
    "    patience_counter = 0  # count epochs without improvement\n",
    "\n",
    "    print('\\n'+'='*70)\n",
    "    print('Starting training')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    # loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "        # training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        # validation\n",
    "        val_loss, val_acc, _, _ = validate_epoch(model, val_loader, criterion)\n",
    "        # update lr\n",
    "        scheduler.step(val_loss)  # adjust lr if val_loss doesn't improve\n",
    "        \n",
    "        # print results\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # save history for graphs\n",
    "        trained_model['train_loss'].append(train_loss)\n",
    "        trained_model['train_acc'].append(train_acc)\n",
    "        trained_model['val_loss'].append(val_loss)\n",
    "        trained_model['val_acc'].append(val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({'epoch':epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'val_acc': val_acc,\n",
    "                        'val_loss': val_loss},\n",
    "                       save_path)\n",
    "            print(f\"✓ Model saved. (Val Acc: {val_acc:.2f}%)\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print('\\n'+'='*70)\n",
    "    print('Training completed')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdef8c9e-37d4-4f73-8c84-a966c46e3eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with: 1600 samples\n",
      "Label mapping: {'pa': 0, 'ta': 1}\n",
      "Class distribution:\n",
      "label\n",
      "pa    800\n",
      "ta    800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset splits (val_split=0.2):\n",
      "Training set: 1280\n",
      "Validation set: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with: 1600 samples\n",
      "Label mapping: {'pa': 0, 'ta': 1}\n",
      "Class distribution:\n",
      "label\n",
      "pa    800\n",
      "ta    800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset splits (val_split=0.2):\n",
      "Training set: 1280\n",
      "Validation set: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with: 1600 samples\n",
      "Label mapping: {'pa': 0, 'ta': 1}\n",
      "Class distribution:\n",
      "label\n",
      "pa    800\n",
      "ta    800\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset splits (val_split=0.2):\n",
      "Training set: 1280\n",
      "Validation set: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# FOR CHECK:\n",
    "import torch.nn as nn\n",
    "import import_ipynb\n",
    "import pytorch_model_05_valid_fn\n",
    "import pytorch_model_04_training_fn\n",
    "import pytorch_model_03_CNN_class\n",
    "import pytorch_model_02_transfoms_dataloaders\n",
    "import pytorch_model_01_dataset_class\n",
    "import torch.optim as optim\n",
    "\n",
    "model = pytorch_model_03_CNN_class.SpectrogramCNN()\n",
    "train_loader, val_loader = pytorch_model_02_transfoms_dataloaders.prepare_data_loaders()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001,weight_decay=0.50)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae56d3af-202d-4178-9b19-04851703a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting training\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6949 | Train Acc: 50.31%\n",
      "Val Loss: 0.6927 | Val Acc: 51.56%\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m+\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m                      \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/Users/hela/Code/pata/best_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler, save_path)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_acc > best_val_acc:\n\u001b[32m     35\u001b[39m     best_val_acc = val_acc\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mtorch\u001b[49m.save({\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m:epoch,\n\u001b[32m     37\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m: model.state_dict(),\n\u001b[32m     38\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33moptimizer_state_dict\u001b[39m\u001b[33m'\u001b[39m: optimizer.state_dict(),\n\u001b[32m     39\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m: val_acc,\n\u001b[32m     40\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m: val_loss},\n\u001b[32m     41\u001b[39m                save_path)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Model saved. (Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m     patience_counter = \u001b[32m0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# CHECK:\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, scheduler, save_path='/Users/hela/Code/pata/best_model.pth'):\n",
    "    trained_model = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}  # dict for graphs\n",
    "    best_val_acc = 0.0\n",
    "    patience = 10  # wait N epochs without improvement before stopping\n",
    "    patience_counter = 0  # count epochs without improvement\n",
    "\n",
    "    print('\\n'+'='*70)\n",
    "    print('Starting training')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    # loop for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "        # training\n",
    "        train_loss, train_acc = pytorch_model_04_training_fn.train_epoch(model, train_loader, criterion, optimizer)\n",
    "        # validation\n",
    "        val_loss, val_acc, _, _ = pytorch_model_05_valid_fn.validate_epoch(model, val_loader, criterion)\n",
    "        # update lr\n",
    "        scheduler.step(val_loss)  # adjust lr if val_loss doesn't improve\n",
    "        \n",
    "        # print results\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # save history for graphs\n",
    "        trained_model['train_loss'].append(train_loss)\n",
    "        trained_model['train_acc'].append(train_acc)\n",
    "        trained_model['val_loss'].append(val_loss)\n",
    "        trained_model['val_acc'].append(val_acc)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({'epoch':epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'val_acc': val_acc,\n",
    "                        'val_loss': val_loss},\n",
    "                       save_path)\n",
    "            print(f\"✓ Model saved. (Val Acc: {val_acc:.2f}%)\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print('\\n'+'='*70)\n",
    "    print('Training completed')\n",
    "    print('='*70+'\\n')\n",
    "\n",
    "    return trained_model\n",
    "    \n",
    "    \n",
    "trained_model = train_model(model=model,\n",
    "                      train_loader=train_loader,\n",
    "                      val_loader=val_loader,\n",
    "                      criterion=criterion,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      num_epochs=10,\n",
    "                      save_path='/Users/hela/Code/pata/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0898b6d-0096-4ae9-951c-646046d8c7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9f47f-538a-4397-a2b1-bdafa3371028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a42e7-9c4b-49b9-98b0-1718d217144d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
